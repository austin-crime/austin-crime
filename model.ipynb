{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434d46d5-d077-410d-be1b-d0d7561f75a0",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "This notebook containing all steps and decisions in the modeling phase of the pipeline.\n",
    "\n",
    "## The Required Imports\n",
    "\n",
    "Here we'll import all the modules required to run the code cells in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbe1263-648c-4421-91aa-5d05daf7823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from wrangle import wrangle_crime_data\n",
    "from prepare import split_data\n",
    "from evaluate import *\n",
    "from model import *\n",
    "\n",
    "# We'll use this random seed for all the machine learning models.\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6d0ba-ce2a-4e1b-a036-2dc636e3adfb",
   "metadata": {},
   "source": [
    "## Acquire, Prepare, and Split the Data\n",
    "\n",
    "Here we'll use the wrangle module to acquire and prepare the data. We'll then split the data into train, validate, and test datasets. The train dataset will be used to train the machine learning models. Validate and test will be used to determine how our models perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbf9665-8b4e-489a-87dc-83349fdd15f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((195764, 346), (83900, 346), (69917, 346))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle_crime_data()\n",
    "df = prep_data_for_modeling(df)\n",
    "\n",
    "train, validate, test = split_data(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042fa0ac-8e3b-4c06-a82f-cca0c51aecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 195764 entries, 128272 to 382883\n",
      "Columns: 346 entries, council_district to WEAPON VIOL - OTHER\n",
      "dtypes: bool(1), float64(4), uint8(341)\n",
      "memory usage: 71.3 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3663d8e-5402-4b69-a002-d4f79a8b6661",
   "metadata": {},
   "source": [
    "## Establish a Baseline\n",
    "\n",
    "We will need to establish a baseline model which will serve as performance reference for our models. The baseline will simply use the simplest approach to predict clearance status (which will be simply predicting the most frequent value). With this reference point will be able to determine if our models at least perform better than the simplest model we could build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c99fdf8-c539-4e32-96b2-571bd5a16072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    195764\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we will establish a baseline model which will always predict the most frequent value in the target variable.\n",
    "\n",
    "baseline = establish_classification_baseline(train.cleared)\n",
    "baseline.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f085ee9-774e-405f-a939-81a0b8c96e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the roc auc score.\n",
    "roc_auc_score(train.cleared, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975b40e2-4edd-476e-8ed9-9129693b80c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883063280276251"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy score.\n",
    "accuracy_score(train.cleared, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667aef3b-4975-4e74-aaf9-38636867d54f",
   "metadata": {},
   "source": [
    "We'll use two metrics to determine the performance of our models: roc auc score and accuracy. Accuracy will tell us how well the model predicts the clearance status of case for our dataset. However, due to the imbalance in our target variable we have to use another metric that will help determine in general how well the model predicts clearance status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3345622-cb92-447c-83f9-e2f15aeb24a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  roc_auc\n",
       "baseline      0.79      0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = append_model_results('baseline', evaluate(train.cleared, baseline, True))\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d74cb7-3c77-4fda-95a5-47ca3e46e3f2",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Before we begin building machine learning models let's use RFE to determine the importance of the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252cdb95-fd66-4350-9737-6f0ce9452547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We'll use RFE to rank the importance of the features in the dataset. We'll use a decision tree classifier \n",
    "# # as the model to compare the features.\n",
    "\n",
    "# rfe = RFE(DecisionTreeClassifier(max_depth = 15), n_features_to_select = 2)\n",
    "# rfe.fit(train.drop(columns = 'cleared'), train.cleared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b61b7c4-8420-4c26-9f46-25ac49d8d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Var': train.drop(columns = 'cleared').columns, 'Rank': rfe.ranking_}).sort_values(by = 'Rank').head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82dcf1-6dd6-48d8-bffb-ffec4630c359",
   "metadata": {},
   "source": [
    "## Initial Set of Models\n",
    "\n",
    "Now we will build a set of initial models to determine which ones have the best performance. We will try building models using various classification algorithms provided by sklearn. These models will be evaluated on the train dataset and the top 3 performing models will be evaluated on validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a66e9fa-5049-40c8-bbde-67830b6a8835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree model, 1.1325089931488037 seconds\n",
      "Training Random Forest model, 5.312100887298584 seconds\n",
      "Training Ada Boost model, 19.786761045455933 seconds\n",
      "Training Bagging Classifier model, 74.75548791885376 seconds\n",
      "Training Gradient Boosting model, 52.34478688240051 seconds\n",
      "Training KNN model, 0.17876291275024414 seconds\n",
      "Training SGD model, 4.529252052307129 seconds\n",
      "Training Naive Bayes model, 0.6548099517822266 seconds\n"
     ]
    }
   ],
   "source": [
    "# All the machine learning model objects will be created using mostly default values with just a few exceptions \n",
    "# such as decision trees which will have a limited depth.\n",
    "\n",
    "algorithms = {\n",
    "    'Decision Tree' : DecisionTreeClassifier(max_depth = 5, random_state = random_seed),\n",
    "    'Random Forest' : RandomForestClassifier(max_depth = 5, random_state = random_seed),\n",
    "    'Ada Boost' : AdaBoostClassifier(random_state = random_seed),\n",
    "    'Bagging Classifier' : BaggingClassifier(random_state = random_seed),\n",
    "    'Gradient Boosting' : GradientBoostingClassifier(random_state = random_seed),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'SGD' : SGDClassifier(random_state = random_seed),\n",
    "    'Naive Bayes' : BernoulliNB()\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for key, algorithm in algorithms.items():\n",
    "    print(f'Training {key} model, ', end = '')\n",
    "    \n",
    "    start = time()\n",
    "    models[key] = Model(\n",
    "        algorithm,\n",
    "        train = train,\n",
    "        features = train.drop(columns = 'cleared').columns,\n",
    "        target = 'cleared'\n",
    "    )\n",
    "    \n",
    "    end = time()\n",
    "    print(f'{end - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a829d7b-95c7-4e13-a7df-165b1a4c5c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree model, 0.32296180725097656 seconds\n",
      "Evaluating Random Forest model, 0.8737740516662598 seconds\n",
      "Evaluating Ada Boost model, 5.832282781600952 seconds\n",
      "Evaluating Bagging Classifier model, 3.4469261169433594 seconds\n",
      "Evaluating Gradient Boosting model, 0.8725049495697021 seconds\n",
      "Evaluating KNN model, 1200.461651802063 seconds\n",
      "Evaluating SGD model, 0.2830479145050049 seconds\n",
      "Evaluating Naive Bayes model, 0.6619489192962646 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  roc_auc\n",
       "baseline                0.79     0.50\n",
       "Decision Tree           0.83     0.61\n",
       "Random Forest           0.79     0.50\n",
       "Ada Boost               0.89     0.79\n",
       "Bagging Classifier      0.97     0.95\n",
       "Gradient Boosting       0.89     0.78\n",
       "KNN                     0.90     0.81\n",
       "SGD                     0.81     0.75\n",
       "Naive Bayes             0.89     0.81"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll evaluate the models.\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'Evaluating {name} model, ', end = '')\n",
    "    \n",
    "    start = time()\n",
    "    eval_df = append_model_results(\n",
    "        name,\n",
    "        evaluate(train.cleared, model.make_predictions(train), True),\n",
    "        eval_df\n",
    "    )\n",
    "    \n",
    "    end = time()\n",
    "    print(f'{end - start} seconds')\n",
    "    \n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfac7f19-01d2-4264-91b8-a5c8fa8f44ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  roc_auc\n",
       "Bagging Classifier      0.97     0.95\n",
       "KNN                     0.90     0.81\n",
       "Naive Bayes             0.89     0.81\n",
       "Ada Boost               0.89     0.79\n",
       "Gradient Boosting       0.89     0.78\n",
       "SGD                     0.81     0.75\n",
       "Decision Tree           0.83     0.61\n",
       "baseline                0.79     0.50\n",
       "Random Forest           0.79     0.50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.sort_values(by = 'roc_auc', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176fbc7-eb60-4b57-952a-01b53c9a2e60",
   "metadata": {},
   "source": [
    "For both metrics the three models with the best performance are the Bagging Classifier, KNN, and Naive Bayes. We'll now evaluate these models on the validate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e362749-cfcf-4b1e-8370-0a3ce28db4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bagging Classifier model, 1.2515251636505127 seconds\n",
      "Evaluating KNN model, 422.44667077064514 seconds\n",
      "Evaluating Naive Bayes model, 0.2880840301513672 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  roc_auc\n",
       "Bagging Classifier      0.89     0.81\n",
       "Naive Bayes             0.89     0.81\n",
       "KNN                     0.87     0.76"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll evaluate the top 3 performing models on validate.\n",
    "algorithms = [\n",
    "    'Bagging Classifier',\n",
    "    'KNN',\n",
    "    'Naive Bayes'\n",
    "]\n",
    "\n",
    "eval_df = None\n",
    "\n",
    "for model in algorithms:\n",
    "    print(f'Evaluating {model} model, ', end = '')\n",
    "    \n",
    "    start = time()\n",
    "    eval_df = append_model_results(\n",
    "        model,\n",
    "        evaluate(validate.cleared, models[model].make_predictions(validate), True),\n",
    "        eval_df\n",
    "    )\n",
    "    \n",
    "    end = time()\n",
    "    print(f'{end - start} seconds')\n",
    "    \n",
    "eval_df.sort_values(by = 'roc_auc', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b287661-b763-46ef-8b2b-6aeaf007d25a",
   "metadata": {},
   "source": [
    "The Naive Bayes model has the same performance on validate as it does on train so we'll evaluate this one on test.\n",
    "\n",
    "## Evaluate Best Model on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9a62ff-6276-4d72-a4e7-eeeb6289778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy  roc_auc\n",
       "Naive Bayes      0.89     0.81"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_model_results(\n",
    "    'Naive Bayes',\n",
    "    evaluate(test.cleared, models['Naive Bayes'].make_predictions(test), True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb0803-dae5-412d-a218-65d22fce4d1d",
   "metadata": {},
   "source": [
    "The Naive Bayes model is 89% accurate on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
